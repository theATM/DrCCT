{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olek/Documents/Projects/Draszcze/DraszczeProject/drenv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/olek/Documents/Projects/Draszcze/DraszczeProject/drenv/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c104impl8GPUTrace13gpuTraceStateE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading pytorch_model.bin:   0%|          | 0.00/346M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c49726f8f19942cbb48d2545e4a419ec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VisionTransformer(\n  (patch_embed): PatchEmbed(\n    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n    (norm): Identity()\n  )\n  (pos_drop): Dropout(p=0.0, inplace=False)\n  (patch_drop): Identity()\n  (norm_pre): Identity()\n  (blocks): Sequential(\n    (0): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate=none)\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (1): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate=none)\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (2): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate=none)\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (3): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate=none)\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (4): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate=none)\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (5): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate=none)\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (6): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate=none)\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (7): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate=none)\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (8): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate=none)\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (9): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate=none)\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (10): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate=none)\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (11): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate=none)\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n  )\n  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n  (fc_norm): Identity()\n  (head_drop): Dropout(p=0.0, inplace=False)\n  (head): Linear(in_features=768, out_features=1000, bias=True)\n)"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm\n",
    "model = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "PretrainedCfg.__init__() got an unexpected keyword argument '_name_or_path'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mjson\u001B[39;00m\n\u001B[1;32m      5\u001B[0m cfg \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mloads(\u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpretrained/vit-base-patch16-224-in21k-config.txt\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mread())\n\u001B[0;32m----> 6\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mtimm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mvit_base_patch16_224\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpretrained\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpretrained_cfg\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcfg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m load \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpretrained/vit-base-patch16-224-in21k.pt\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      8\u001B[0m model\u001B[38;5;241m.\u001B[39mload_state_dict(load)\n",
      "File \u001B[0;32m~/Documents/Projects/Draszcze/DraszczeProject/timm/models/_factory.py:93\u001B[0m, in \u001B[0;36mcreate_model\u001B[0;34m(model_name, pretrained, pretrained_cfg, pretrained_cfg_overlay, checkpoint_path, scriptable, exportable, no_jit, **kwargs)\u001B[0m\n\u001B[1;32m     91\u001B[0m create_fn \u001B[38;5;241m=\u001B[39m model_entrypoint(model_name)\n\u001B[1;32m     92\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m set_layer_config(scriptable\u001B[38;5;241m=\u001B[39mscriptable, exportable\u001B[38;5;241m=\u001B[39mexportable, no_jit\u001B[38;5;241m=\u001B[39mno_jit):\n\u001B[0;32m---> 93\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_fn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     94\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpretrained\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpretrained\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     95\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpretrained_cfg\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpretrained_cfg\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     96\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpretrained_cfg_overlay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpretrained_cfg_overlay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     97\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     98\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m checkpoint_path:\n\u001B[1;32m    101\u001B[0m     load_checkpoint(model, checkpoint_path)\n",
      "File \u001B[0;32m~/Documents/Projects/Draszcze/DraszczeProject/timm/models/vision_transformer.py:1426\u001B[0m, in \u001B[0;36mvit_base_patch16_224\u001B[0;34m(pretrained, **kwargs)\u001B[0m\n\u001B[1;32m   1422\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\" ViT-Base (ViT-B/16) from original paper (https://arxiv.org/abs/2010.11929).\u001B[39;00m\n\u001B[1;32m   1423\u001B[0m \u001B[38;5;124;03mImageNet-1k weights fine-tuned from in21k @ 224x224, source https://github.com/google-research/vision_transformer.\u001B[39;00m\n\u001B[1;32m   1424\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1425\u001B[0m model_args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(patch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m, embed_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m768\u001B[39m, depth\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m12\u001B[39m, num_heads\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m12\u001B[39m)\n\u001B[0;32m-> 1426\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43m_create_vision_transformer\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mvit_base_patch16_224\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpretrained\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpretrained\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mdict\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1427\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[0;32m~/Documents/Projects/Draszcze/DraszczeProject/timm/models/vision_transformer.py:1330\u001B[0m, in \u001B[0;36m_create_vision_transformer\u001B[0;34m(variant, pretrained, **kwargs)\u001B[0m\n\u001B[1;32m   1327\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1328\u001B[0m     _filter_fn \u001B[38;5;241m=\u001B[39m checkpoint_filter_fn\n\u001B[0;32m-> 1330\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mbuild_model_with_cfg\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1331\u001B[0m \u001B[43m    \u001B[49m\u001B[43mVisionTransformer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvariant\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpretrained\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1332\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpretrained_filter_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_filter_fn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1333\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1334\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Projects/Draszcze/DraszczeProject/timm/models/_builder.py:351\u001B[0m, in \u001B[0;36mbuild_model_with_cfg\u001B[0;34m(model_cls, variant, pretrained, pretrained_cfg, pretrained_cfg_overlay, model_cfg, feature_cfg, pretrained_strict, pretrained_filter_fn, kwargs_filter, **kwargs)\u001B[0m\n\u001B[1;32m    348\u001B[0m feature_cfg \u001B[38;5;241m=\u001B[39m feature_cfg \u001B[38;5;129;01mor\u001B[39;00m {}\n\u001B[1;32m    350\u001B[0m \u001B[38;5;66;03m# resolve and update model pretrained config and model kwargs\u001B[39;00m\n\u001B[0;32m--> 351\u001B[0m pretrained_cfg \u001B[38;5;241m=\u001B[39m \u001B[43mresolve_pretrained_cfg\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    352\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvariant\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    353\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpretrained_cfg\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpretrained_cfg\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpretrained_cfg_overlay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpretrained_cfg_overlay\u001B[49m\n\u001B[1;32m    355\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    357\u001B[0m \u001B[38;5;66;03m# FIXME converting back to dict, PretrainedCfg use should be propagated further, but not into model\u001B[39;00m\n\u001B[1;32m    358\u001B[0m pretrained_cfg \u001B[38;5;241m=\u001B[39m pretrained_cfg\u001B[38;5;241m.\u001B[39mto_dict()\n",
      "File \u001B[0;32m~/Documents/Projects/Draszcze/DraszczeProject/timm/models/_builder.py:288\u001B[0m, in \u001B[0;36mresolve_pretrained_cfg\u001B[0;34m(variant, pretrained_cfg, pretrained_cfg_overlay)\u001B[0m\n\u001B[1;32m    285\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pretrained_cfg:\n\u001B[1;32m    286\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(pretrained_cfg, \u001B[38;5;28mdict\u001B[39m):\n\u001B[1;32m    287\u001B[0m         \u001B[38;5;66;03m# pretrained_cfg dict passed as arg, validate by converting to PretrainedCfg\u001B[39;00m\n\u001B[0;32m--> 288\u001B[0m         pretrained_cfg \u001B[38;5;241m=\u001B[39m \u001B[43mPretrainedCfg\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpretrained_cfg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    289\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(pretrained_cfg, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    290\u001B[0m         pretrained_tag \u001B[38;5;241m=\u001B[39m pretrained_cfg\n",
      "\u001B[0;31mTypeError\u001B[0m: PretrainedCfg.__init__() got an unexpected keyword argument '_name_or_path'"
     ]
    }
   ],
   "source": [
    "#import timm\n",
    "#import torch\n",
    "#import json\n",
    "#\n",
    "#cfg = json.loads(open('pretrained/vit-base-patch16-224-in21k-config.txt','r').read())\n",
    "#model = timm.create_model('vit_base_patch16_224', pretrained=False, pretrained_cfg=cfg)\n",
    "#load = torch.load('pretrained/vit-base-patch16-224-in21k.pt')\n",
    "#model.load_state_dict(load)\n",
    "#model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m torch\u001B[38;5;241m.\u001B[39msave(\u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39mstate_dict(),\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpretrained/vit_base_patch16_224.pt\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.save(model.state_dict(),'pretrained/vit_base_patch16_224.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "VisionTransformer(\n  (patch_embed): PatchEmbed(\n    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n    (norm): Identity()\n  )\n  (pos_drop): Dropout(p=0.0, inplace=False)\n  (patch_drop): Identity()\n  (norm_pre): Identity()\n  (blocks): Sequential(\n    (0): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (1): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (2): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (3): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (4): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (5): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (6): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (7): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (8): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (9): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (10): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (11): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n  )\n  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n  (fc_norm): Identity()\n  (head_drop): Dropout(p=0.0, inplace=False)\n  (head): Linear(in_features=768, out_features=1000, bias=True)\n)"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "load = torch.load('pretrained/vit_base_patch16_224.pt')\n",
    "import timm\n",
    "\n",
    "model = timm.create_model('vit_base_patch16_224', pretrained=False)\n",
    "model.load_state_dict(load)\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "VisionTransformer(\n  (patch_embed): PatchEmbed(\n    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n    (norm): Identity()\n  )\n  (pos_drop): Dropout(p=0.0, inplace=False)\n  (patch_drop): Identity()\n  (norm_pre): Identity()\n  (blocks): Sequential(\n    (0): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (1): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (2): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (3): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (4): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (5): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (6): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (7): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (8): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (9): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (10): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (11): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n  )\n  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n  (fc_norm): Identity()\n  (head_drop): Dropout(p=0.0, inplace=False)\n  (head): Linear(in_features=768, out_features=1000, bias=True)\n)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import timm\n",
    "from timm.models.vision_transformer import VisionTransformer\n",
    "vi = VisionTransformer()\n",
    "load = torch.load('pretrained/vit_base_patch16_224.pt')\n",
    "vi.load_state_dict(load)\n",
    "vi.eval()\n",
    "vi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import urllib\n",
    "from PIL import Image\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "\n",
    "config = resolve_data_config({}, model=model)\n",
    "transform = create_transform(**config)\n",
    "\n",
    "#url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
    "#urllib.request.urlretrieve(url, filename)\n",
    "img = Image.open('dog.jpg').convert('RGB')\n",
    "tensor = transform(img).unsqueeze(0) # transform and add batch dimension"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "with torch.no_grad():\n",
    "    out = model(tensor)\n",
    "probabilities = torch.nn.functional.softmax(out[0], dim=0)\n",
    "print(probabilities.shape)\n",
    "# prints: torch.Size([1000])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samoyed 0.8376525044441223\n",
      "keeshond 0.01916642300784588\n",
      "Pomeranian 0.01694728061556816\n",
      "kuvasz 0.006354726850986481\n",
      "Great Pyrenees 0.004615336190909147\n"
     ]
    }
   ],
   "source": [
    "# Get imagenet class mappings\n",
    "#url, filename = (\"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\", \"imagenet_classes.txt\")\n",
    "#urllib.request.urlretrieve(url, filename)\n",
    "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]\n",
    "\n",
    "# Print top categories per image\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "for i in range(top5_prob.size(0)):\n",
    "    print(categories[top5_catid[i]], top5_prob[i].item())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "ViT(\n  (to_patch_embedding): Sequential(\n    (0): Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=16, p2=16)\n    (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    (2): Linear(in_features=768, out_features=768, bias=True)\n    (3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (dropout): Dropout(p=0.0, inplace=False)\n  (transformer): Transformer(\n    (layers): ModuleList(\n      (0): ModuleList(\n        (0): PreNorm(\n          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fn): Attention(\n            (attend): Softmax(dim=-1)\n            (dropout): Dropout(p=0.0, inplace=False)\n            (to_qkv): Linear(in_features=768, out_features=2304, bias=False)\n            (to_out): Sequential(\n              (0): Linear(in_features=768, out_features=768, bias=True)\n              (1): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (1): PreNorm(\n          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fn): FeedForward(\n            (net): Sequential(\n              (0): Linear(in_features=768, out_features=3072, bias=True)\n              (1): GELU(approximate='none')\n              (2): Dropout(p=0.0, inplace=False)\n              (3): Linear(in_features=3072, out_features=768, bias=True)\n              (4): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n      )\n      (1): ModuleList(\n        (0): PreNorm(\n          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fn): Attention(\n            (attend): Softmax(dim=-1)\n            (dropout): Dropout(p=0.0, inplace=False)\n            (to_qkv): Linear(in_features=768, out_features=2304, bias=False)\n            (to_out): Sequential(\n              (0): Linear(in_features=768, out_features=768, bias=True)\n              (1): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (1): PreNorm(\n          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fn): FeedForward(\n            (net): Sequential(\n              (0): Linear(in_features=768, out_features=3072, bias=True)\n              (1): GELU(approximate='none')\n              (2): Dropout(p=0.0, inplace=False)\n              (3): Linear(in_features=3072, out_features=768, bias=True)\n              (4): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n      )\n      (2): ModuleList(\n        (0): PreNorm(\n          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fn): Attention(\n            (attend): Softmax(dim=-1)\n            (dropout): Dropout(p=0.0, inplace=False)\n            (to_qkv): Linear(in_features=768, out_features=2304, bias=False)\n            (to_out): Sequential(\n              (0): Linear(in_features=768, out_features=768, bias=True)\n              (1): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (1): PreNorm(\n          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fn): FeedForward(\n            (net): Sequential(\n              (0): Linear(in_features=768, out_features=3072, bias=True)\n              (1): GELU(approximate='none')\n              (2): Dropout(p=0.0, inplace=False)\n              (3): Linear(in_features=3072, out_features=768, bias=True)\n              (4): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n      )\n      (3): ModuleList(\n        (0): PreNorm(\n          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fn): Attention(\n            (attend): Softmax(dim=-1)\n            (dropout): Dropout(p=0.0, inplace=False)\n            (to_qkv): Linear(in_features=768, out_features=2304, bias=False)\n            (to_out): Sequential(\n              (0): Linear(in_features=768, out_features=768, bias=True)\n              (1): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (1): PreNorm(\n          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fn): FeedForward(\n            (net): Sequential(\n              (0): Linear(in_features=768, out_features=3072, bias=True)\n              (1): GELU(approximate='none')\n              (2): Dropout(p=0.0, inplace=False)\n              (3): Linear(in_features=3072, out_features=768, bias=True)\n              (4): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n      )\n      (4): ModuleList(\n        (0): PreNorm(\n          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fn): Attention(\n            (attend): Softmax(dim=-1)\n            (dropout): Dropout(p=0.0, inplace=False)\n            (to_qkv): Linear(in_features=768, out_features=2304, bias=False)\n            (to_out): Sequential(\n              (0): Linear(in_features=768, out_features=768, bias=True)\n              (1): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (1): PreNorm(\n          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fn): FeedForward(\n            (net): Sequential(\n              (0): Linear(in_features=768, out_features=3072, bias=True)\n              (1): GELU(approximate='none')\n              (2): Dropout(p=0.0, inplace=False)\n              (3): Linear(in_features=3072, out_features=768, bias=True)\n              (4): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n      )\n      (5): ModuleList(\n        (0): PreNorm(\n          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fn): Attention(\n            (attend): Softmax(dim=-1)\n            (dropout): Dropout(p=0.0, inplace=False)\n            (to_qkv): Linear(in_features=768, out_features=2304, bias=False)\n            (to_out): Sequential(\n              (0): Linear(in_features=768, out_features=768, bias=True)\n              (1): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (1): PreNorm(\n          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fn): FeedForward(\n            (net): Sequential(\n              (0): Linear(in_features=768, out_features=3072, bias=True)\n              (1): GELU(approximate='none')\n              (2): Dropout(p=0.0, inplace=False)\n              (3): Linear(in_features=3072, out_features=768, bias=True)\n              (4): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n      )\n      (6): ModuleList(\n        (0): PreNorm(\n          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fn): Attention(\n            (attend): Softmax(dim=-1)\n            (dropout): Dropout(p=0.0, inplace=False)\n            (to_qkv): Linear(in_features=768, out_features=2304, bias=False)\n            (to_out): Sequential(\n              (0): Linear(in_features=768, out_features=768, bias=True)\n              (1): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (1): PreNorm(\n          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fn): FeedForward(\n            (net): Sequential(\n              (0): Linear(in_features=768, out_features=3072, bias=True)\n              (1): GELU(approximate='none')\n              (2): Dropout(p=0.0, inplace=False)\n              (3): Linear(in_features=3072, out_features=768, bias=True)\n              (4): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n      )\n      (7): ModuleList(\n        (0): PreNorm(\n          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fn): Attention(\n            (attend): Softmax(dim=-1)\n            (dropout): Dropout(p=0.0, inplace=False)\n            (to_qkv): Linear(in_features=768, out_features=2304, bias=False)\n            (to_out): Sequential(\n              (0): Linear(in_features=768, out_features=768, bias=True)\n              (1): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (1): PreNorm(\n          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fn): FeedForward(\n            (net): Sequential(\n              (0): Linear(in_features=768, out_features=3072, bias=True)\n              (1): GELU(approximate='none')\n              (2): Dropout(p=0.0, inplace=False)\n              (3): Linear(in_features=3072, out_features=768, bias=True)\n              (4): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n      )\n      (8): ModuleList(\n        (0): PreNorm(\n          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fn): Attention(\n            (attend): Softmax(dim=-1)\n            (dropout): Dropout(p=0.0, inplace=False)\n            (to_qkv): Linear(in_features=768, out_features=2304, bias=False)\n            (to_out): Sequential(\n              (0): Linear(in_features=768, out_features=768, bias=True)\n              (1): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (1): PreNorm(\n          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fn): FeedForward(\n            (net): Sequential(\n              (0): Linear(in_features=768, out_features=3072, bias=True)\n              (1): GELU(approximate='none')\n              (2): Dropout(p=0.0, inplace=False)\n              (3): Linear(in_features=3072, out_features=768, bias=True)\n              (4): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n      )\n      (9): ModuleList(\n        (0): PreNorm(\n          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fn): Attention(\n            (attend): Softmax(dim=-1)\n            (dropout): Dropout(p=0.0, inplace=False)\n            (to_qkv): Linear(in_features=768, out_features=2304, bias=False)\n            (to_out): Sequential(\n              (0): Linear(in_features=768, out_features=768, bias=True)\n              (1): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (1): PreNorm(\n          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fn): FeedForward(\n            (net): Sequential(\n              (0): Linear(in_features=768, out_features=3072, bias=True)\n              (1): GELU(approximate='none')\n              (2): Dropout(p=0.0, inplace=False)\n              (3): Linear(in_features=3072, out_features=768, bias=True)\n              (4): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n      )\n      (10): ModuleList(\n        (0): PreNorm(\n          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fn): Attention(\n            (attend): Softmax(dim=-1)\n            (dropout): Dropout(p=0.0, inplace=False)\n            (to_qkv): Linear(in_features=768, out_features=2304, bias=False)\n            (to_out): Sequential(\n              (0): Linear(in_features=768, out_features=768, bias=True)\n              (1): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (1): PreNorm(\n          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fn): FeedForward(\n            (net): Sequential(\n              (0): Linear(in_features=768, out_features=3072, bias=True)\n              (1): GELU(approximate='none')\n              (2): Dropout(p=0.0, inplace=False)\n              (3): Linear(in_features=3072, out_features=768, bias=True)\n              (4): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n      )\n      (11): ModuleList(\n        (0): PreNorm(\n          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fn): Attention(\n            (attend): Softmax(dim=-1)\n            (dropout): Dropout(p=0.0, inplace=False)\n            (to_qkv): Linear(in_features=768, out_features=2304, bias=False)\n            (to_out): Sequential(\n              (0): Linear(in_features=768, out_features=768, bias=True)\n              (1): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (1): PreNorm(\n          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fn): FeedForward(\n            (net): Sequential(\n              (0): Linear(in_features=768, out_features=3072, bias=True)\n              (1): GELU(approximate='none')\n              (2): Dropout(p=0.0, inplace=False)\n              (3): Linear(in_features=3072, out_features=768, bias=True)\n              (4): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n      )\n    )\n  )\n  (to_latent): Identity()\n  (mlp_head): Sequential(\n    (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    (1): Linear(in_features=768, out_features=1000, bias=True)\n  )\n)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Vit.vit import ViT\n",
    "vit_model = ViT(\n",
    "    image_size = 384,\n",
    "    patch_size = 16,\n",
    "    num_classes = 1000,\n",
    "    dim = 768,\n",
    "    depth = 12,\n",
    "    heads = 12,\n",
    "    mlp_dim = 3072\n",
    ")\n",
    "vit_model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vit_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " dict(patch_size=16, embed_dim=768, depth=12, num_heads=12)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from Vit.learnable_memory_vit import Adapter\n",
    "# then, to finetune, just pass the ViT into the Adapter class\n",
    "# you can do this for multiple Adapters, as shown below\n",
    "\n",
    "adapter1 = Adapter(\n",
    "    vit = v,\n",
    "    num_classes = 2,               # number of output classes for this specific task\n",
    "    num_memories_per_layer = 5     # number of learnable memories per layer, 10 was sufficient in paper\n",
    ")\n",
    "\n",
    "logits1 = adapter1(img) # (4, 2) - predict 2 classes off frozen ViT backbone with learnable memories and task specific head\n",
    "\n",
    "# yet another task to finetune on, this time with 4 classes\n",
    "\n",
    "adapter2 = Adapter(\n",
    "    vit = v,\n",
    "    num_classes = 4,\n",
    "    num_memories_per_layer = 10\n",
    ")\n",
    "\n",
    "logits2 = adapter2(img) # (4, 4) - predict 4 classes off frozen ViT backbone with learnable memories and task specific head"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}